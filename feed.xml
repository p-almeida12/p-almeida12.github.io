<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://p-almeida12.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://p-almeida12.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-07T00:41:52+00:00</updated><id>https://p-almeida12.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Big O Notation for Developers</title><link href="https://p-almeida12.github.io/blog/2024/big-o-notation/" rel="alternate" type="text/html" title="Big O Notation for Developers"/><published>2024-06-02T14:59:00+00:00</published><updated>2024-06-02T14:59:00+00:00</updated><id>https://p-almeida12.github.io/blog/2024/big-o-notation</id><content type="html" xml:base="https://p-almeida12.github.io/blog/2024/big-o-notation/"><![CDATA[<p><span style="margin-left: 10px;"></span> In the realm of computer science and software development, efficiency is extremely important. As the size of data and the complexity of operations increases, the performance of algorithms becomes a critical concern. Big O Notation is a mathematical concept that helps programmers understand and quantify the efficiency of their algorithms. In school, we always wondered why we needed math, all those formulas and equations with no sight of numbers. Well, Big O Notation is one of the reasons why math is essential in programming, and although we don’t like it, it is a necessary evil that can be of great help in optimizing our code.</p> <p><span style="margin-left: 10px;"></span> In this article, we explore the essential concept of Big O Notation and its significance in the world of programming. Understanding Big O Notation is crucial for evaluating and optimizing the performance of algorithms, ensuring efficient and scalable code. We will delve into what Big O Notation is, how it helps in analyzing algorithm complexity, and why mastering it is vital for every programmer aiming to write high-performance software.</p> <h2 id="what-is-big-o-notation">What is Big O Notation?</h2> <h3 id="definition-and-purpose">Definition and Purpose</h3> <p><span style="margin-left: 10px;"></span> Big O Notation is a mathematical concept used in computer science to describe the efficiency of algorithms in terms of time and space complexity. It provides a way to classify algorithms according to how their run time or space requirements grow as the input size increases. The primary purpose of Big O Notation is to give programmers a high-level understanding of the performance characteristics of an algorithm without getting lost in implementation details [<a href="https://www.simplilearn.com/big-o-notation-in-data-structure-article">https://www.simplilearn.com/big-o-notation-in-data-structure-article</a>].</p> <p><span style="margin-left: 10px;"></span> In essence, Big O Notation helps answer the question: “How does the algorithm’s performance change as the input size grows?” By focusing on the largest contributing factors, Big O Notation abstracts away constants and lower-order terms, allowing for a simplified analysis of an algorithm’s efficiency.</p> <h3 id="how-it-measures-time-and-space-complexity">How it Measures Time and Space Complexity</h3> <p><span style="margin-left: 10px;"></span> Time complexity refers to the amount of time an algorithm takes to complete as a function of the input size. It is measured in terms of the number of fundamental operations an algorithm performs relative to the size of the input. The key here is to understand how the time scales as the input size grows. For example, for an algorithm with a time complexity of O(n), the number of operations increases linearly with the input size. If the input size doubles, the time it takes to complete the algorithm also doubles.</p> <p><span style="margin-left: 10px;"></span> On the other hand, space complexity refers to the amount of memory an algorithm uses as a function of the input size. Space complexity measures the extra space or memory required by the algorithm, not counting the space needed for the input itself. Like time complexity, it focuses on how the memory requirements grow with the input size. For example, for an algorithm with a space complexity of O(n), the amount of memory needed grows linearly with the input size. If the input size doubles, the memory usage also doubles, following the same thought of the time complexity.</p> <h2 id="why-is-big-o-notation-important">Why is Big O Notation Important?</h2> <p><span style="margin-left: 10px;"></span> Understanding and applying Big O Notation is crucial for efficiency, scalability, and overall quality of software applications. Big O Notation is essential for programmers as it helps identify and select the most efficient algorithms based on their time complexity. By understanding how different algorithms scale with input size, developers can choose those that handle larger datasets or insert/delete more effectively. For instance, an algorithm with O(n log n) complexity will outperform an O(n^2) algorithm as data size increases. This knowledge is crucial for optimizing application performance, resulting in faster execution times and a better user experience.</p> <p><span style="margin-left: 10px;"></span> To make this analysis, we need to understand the existent Big O notations and how structures and algorithms are classified. Of course, we can’t know all of them, but keeping a cheat sheet handy can be a good idea. Further down this post, I will provide a table with the most common Big O notations.</p> <p><span style="margin-left: 10px;"></span> Scalability is another critical aspect addressed by Big O Notation. As applications grow and process more data, it’s crucial to ensure algorithms can scale efficiently. Algorithms with lower complexity usually ensure applications remain performant under increasing user loads, such as in web applications handling large and continuously growing<br/> amounts of user data.</p> <p><span style="margin-left: 10px;"></span> Moreover, Big O Notation promotes high code quality by encouraging developers to write clean, efficient, and maintainable code. Well-designed algorithms with optimal complexity not only perform better but also tend to be more readable and easier to maintain, leading to fewer bugs and simpler debugging processes.</p> <p><span style="margin-left: 10px;"></span> In conclusion, Big O Notation serves as a foundational tool for every programmer, providing insights into algorithm efficiency and scalability. By focusing on performance optimization, scalability, resource management, and code quality, developers can create robust, high-performance software capable of meeting the demands of today’s software.</p> <h2 id="common-big-o-notations">Common Big O Notations</h2> <p><span style="margin-left: 10px;"></span> Here are the most commonly encountered Big O Notations, along with their definitions and examples:</p> <table> <thead> <tr> <th style="text-align: left">Complexity</th> <th style="text-align: center">Name</th> <th style="text-align: right">Example</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">O(1)</td> <td style="text-align: center">Constant</td> <td style="text-align: right">Accessing an element in an array</td> </tr> <tr> <td style="text-align: left">O(log n)</td> <td style="text-align: center">Logarithmic</td> <td style="text-align: right">Binary search in a sorted array</td> </tr> <tr> <td style="text-align: left">O(n)</td> <td style="text-align: center">Linear</td> <td style="text-align: right">Iterating through an array</td> </tr> <tr> <td style="text-align: left">O(n log n)</td> <td style="text-align: center">Linearithmic</td> <td style="text-align: right">Efficient sorting algorithms (e.g., mergesort)</td> </tr> <tr> <td style="text-align: left">O(n^2)</td> <td style="text-align: center">Quadratic</td> <td style="text-align: right">Simple sorting algorithms (e.g., bubble sort)</td> </tr> <tr> <td style="text-align: left">O(2^n)</td> <td style="text-align: center">Exponential</td> <td style="text-align: right">Solving the Tower of Hanoi problem</td> </tr> <tr> <td style="text-align: left">O(n!)</td> <td style="text-align: center">Factorial</td> <td style="text-align: right">Generating all permutations of a list</td> </tr> </tbody> </table> <p><span style="margin-left: 10px;"></span> I don’t think it’s necessary to further elaborate on the Big O Notation mentioned above, as they are self-explanatory.</p> <h2 id="importance-in-modern-software-development">Importance in Modern Software Development</h2> <p><span style="margin-left: 10px;"></span> In today’s fast-paced software development landscape, the ability to write efficient code is more critical than ever. With the exponential growth of data and the increasing complexity of operations, the performance of algorithms directly impacts the user experience and the scalability of applications. Big O Notation plays an extremely important role in modern software development by providing a framework for understanding and improving algorithm efficiency.</p> <p><span style="margin-left: 10px;"></span> Real-world applications often deal with vast amounts of data, whether it’s in search engines processing billions of queries per day, social media platforms managing terabytes of user-generated content, or financial systems executing thousands of transactions per second. In these scenarios, the choice of algorithms can significantly influence performance. By leveraging algorithms with optimal Big O characteristics, developers can ensure their applications remain performant and responsive under heavy loads.</p> <h2 id="case-studies-and-practical-examples">Case Studies and Practical Examples</h2> <p><span style="margin-left: 10px;"></span> To illustrate the practical applications of Big O Notation, let’s consider these 2 case studies of well-known algorithms that we encounter in everyday software development:</p> <h3 id="sorting-algorithms-quicksort-vs-bubble-sort">Sorting Algorithms: Quicksort vs. Bubble Sort</h3> <h4 id="quicksort">Quicksort:</h4> <ul> <li>Time Complexity of O(n log n) -&gt; on average</li> <li>How It Works: Quicksort is a divide-and-conquer algorithm. It works by selecting a ‘pivot’ element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then sorted recursively.</li> <li>Efficiency: On average, Quicksort is very efficient, dividing the problem in half with each recursive call, leading to an average time complexity of O(n log n). This makes it suitable for large datasets.</li> </ul> <h4 id="bubble-sort">Bubble Sort:</h4> <ul> <li>Time Complexity: O(n^2) -&gt; on average</li> <li>How It Works: Bubble Sort is a simple comparison-based algorithm. It repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. This process is repeated until the list is sorted.</li> <li>Efficiency: Bubble Sort performs poorly on large datasets because it makes multiple passes through the list, with each pass having O(n) comparisons and potentially O(n) swaps, resulting in an overall time complexity of O(n^2).</li> </ul> <h4 id="comparison">Comparison:</h4> <p><span style="margin-left: 10px;"></span> For a dataset with 10,000 elements, Quicksort would, on average, take about 10,000 * log(10,000) = 10,000 * 4 = 40,000 operations.</p> <p><span style="margin-left: 10px;"></span> Bubble Sort, on the other hand, would take approximately 10,000 * 10,000 = 100,000,000 operations.</p> <p><span style="margin-left: 10px;"></span> According to this article <a href="https://mertmetin-1.medium.com/introduction-a12c801927a2">Bubble Sort Vs Quick Sort Algorithms</a>, as the dataset grows, the difference in performance becomes more pronounced. This example highlights why choosing Quicksort over Bubble Sort can lead to significant performance improvements for large datasets.</p> <h3 id="searching-algorithms-binary-search-vs-linear-search">Searching Algorithms: Binary Search vs. Linear Search</h3> <p><span style="margin-left: 10px;"></span> Searching is another common operation where algorithm choice is crucial for performance. Let’s compare Binary Search and Linear Search.</p> <h4 id="binary-search">Binary Search:</h4> <ul> <li>Time Complexity: O(log n)</li> <li>How It Works: Binary Search requires the array to be sorted. It works by repeatedly dividing the search interval in half. If the value of the search key is less than the item in the middle of the interval, it narrows the interval to the lower half. Otherwise, it narrows it to the upper half. The process continues until the value is found or the interval is empty.</li> <li>Efficiency: Binary Search is highly efficient for large datasets because it reduces the problem size by half with each step. This logarithmic time complexity makes it much faster than linear search for large arrays.</li> </ul> <h4 id="linear-search">Linear Search:</h4> <ul> <li>Time Complexity: O(n)</li> <li>How It Works: Linear Search scans each element of the array sequentially until the desired value is found or the end of the array is reached.</li> <li>Efficiency: Linear Search performs well for small arrays or unsorted data but becomes inefficient as the size of the dataset increases because each element must be checked, resulting in a linear time complexity.</li> </ul> <h4 id="comparison-1">Comparison:</h4> <p><span style="margin-left: 10px;"></span> For a dataset with 1,000,000 elements, Binary Search would take log(1,000,000) ≈ 20 comparisons. Linear Search, in the worst case, would take up to 1,000,000 comparisons. As the dataset grows, Binary Search’s efficiency becomes even more significant. For instance, doubling the size of the dataset to 2,000,000 elements would only increase Binary Search comparisons to 21, while Linear Search comparisons would double to 2,000,000.</p> <p><span style="margin-left: 10px;"></span> By analyzing this study <a href="https://www.geeksforgeeks.org/linear-search-vs-binary-search/">Linear Search vs Binary Search</a> we can understand the importance of Big O Notation to select and implement the most efficient algorithms for specific tasks.</p> <h2 id="big-o-notation-for-developers">Big O Notation for Developers</h2> <p><span style="margin-left: 10px;"></span> Big O Notation is a fundamental concept in computer science that every developer should understand. It provides a high-level understanding of the efficiency of algorithms by describing their time and space complexity. For developers, understanding Big O Notation is crucial for writing efficient, scalable, and high-performance code.</p> <p><span style="margin-left: 10px;"></span> Java developers often deal with a variety of data structures and algorithms provided by the Java Collections Framework. Understanding the Big O Notation of these data structures and algorithms helps in making informed decisions when writing and optimizing code.</p> <h3 id="comparison-table-of-java-data-structures">Comparison Table of Java Data Structures</h3> <table> <thead> <tr> <th>Data Structure</th> <th>Access Time</th> <th>Insertion Time</th> <th>Deletion Time</th> <th>Order Preserved</th> <th>Best Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>ArrayList</strong></td> <td>O(1)</td> <td>O(n)</td> <td>O(n)</td> <td>No</td> <td>Random access</td> </tr> <tr> <td><strong>LinkedList</strong></td> <td>O(n)</td> <td>O(1) at ends</td> <td>O(1) at ends</td> <td>No</td> <td>Frequent insertions/deletions at ends</td> </tr> <tr> <td><strong>HashSet</strong></td> <td>O(1)</td> <td>O(1)</td> <td>O(1)</td> <td>No</td> <td>Unique elements with fast lookups</td> </tr> <tr> <td><strong>LinkedHashSet</strong></td> <td>O(1)</td> <td>O(1)</td> <td>O(1)</td> <td>Yes</td> <td>Unique elements with insertion order maintained</td> </tr> <tr> <td><strong>TreeSet</strong></td> <td>O(log n)</td> <td>O(log n)</td> <td>O(log n)</td> <td>Yes (Sorted)</td> <td>Sorted unique elements</td> </tr> <tr> <td><strong>HashMap</strong></td> <td>O(1)</td> <td>O(1)</td> <td>O(1)</td> <td>No</td> <td>Fast key-value lookups</td> </tr> <tr> <td><strong>LinkedHashMap</strong></td> <td>O(1)</td> <td>O(1)</td> <td>O(1)</td> <td>Yes</td> <td>Fast lookups with insertion order maintained</td> </tr> <tr> <td><strong>TreeMap</strong></td> <td>O(log n)</td> <td>O(log n)</td> <td>O(log n)</td> <td>Yes (Sorted)</td> <td>Sorted key-value pairs</td> </tr> </tbody> </table> <p><span style="margin-left: 10px;"></span> When choosing a data structure, Java developers need to consider the typical operations their application will perform. For example, if fast lookups are crucial, a HashMap might be the best choice. However, if ordered data is needed, a TreeMap or LinkedList might be more appropriate despite their higher access times.</p> <h3 id="comparison-table-of-java-sorting-algorithms">Comparison Table of Java Sorting Algorithms</h3> <table> <thead> <tr> <th>Sorting Algorithm</th> <th>Time Complexity (Best)</th> <th>Time Complexity (Average)</th> <th>Time Complexity (Worst)</th> <th>Space Complexity</th> <th>Best Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>Collections.sort()</strong> (Timsort)</td> <td>O(n)</td> <td>O(n log n)</td> <td>O(n log n)</td> <td>O(n)</td> <td>For general-purpose sorting with objects</td> </tr> <tr> <td><strong>Arrays.sort()</strong> (Dual-Pivot Quicksort)</td> <td>O(n log n)</td> <td>O(n log n)</td> <td>O(n^2)</td> <td>O(log n)</td> <td>For sorting arrays of primitive types</td> </tr> <tr> <td><strong>Quicksort</strong></td> <td>O(n log n)</td> <td>O(n log n)</td> <td>O(n^2)</td> <td>O(log n)</td> <td>Fast in practice for large datasets</td> </tr> <tr> <td><strong>Mergesort</strong></td> <td>O(n log n)</td> <td>O(n log n)</td> <td>O(n log n)</td> <td>O(n)</td> <td>Linked lists or when stability is crucial</td> </tr> </tbody> </table> <p><span style="margin-left: 10px;"></span> Sorting algorithms are another critical area where Big O Notation comes into play. Java’s Collections.sort() method uses Timsort, which has a time complexity of O(n log n). Knowing this helps developers understand that the sorting operation will scale efficiently with the size of the data.</p> <p><span style="margin-left: 10px;"></span> For backend web developers, efficiency and scalability are paramount. Understanding Big O Notation helps in optimizing server-side code to handle increasing loads and large datasets.</p> <h4 id="database-queries">Database Queries:</h4> <p>Understanding the time complexity of database operations is essential. For instance, indexing can reduce query time complexity from O(n) to O(log n). However, too many indexes can increase the time complexity of insertions and updates.</p> <h4 id="api-response-times">API Response Times:</h4> <p>Optimizing algorithms that process data before sending responses can significantly impact API performance. For example, filtering and sorting operations on server-side collections should use efficient algorithms to ensure fast response times.</p> <h4 id="caching-strategies">Caching Strategies:</h4> <p>Caching frequently accessed data can reduce the time complexity of retrieval operations from O(n) to O(1). Implementing efficient cache eviction practices can also be analyzed using Big O Notation to ensure optimal performance.</p> <p><span style="margin-left: 10px;"></span> When designing APIs, backend developers need to be mindful of the algorithms they use for data processing. For example, an API endpoint that sorts a large list of users should use a sorting algorithm with O(n log n) complexity rather than O(n^2).</p> <p><span style="margin-left: 10px;"></span> In addition, understanding the space complexity of data structures can help in managing memory usage effectively. For example, using a linked list for a large dataset might lead to high memory overhead due to the storage of pointers, whereas an array-based list might be more memory-efficient.</p> <h2 id="conclusion">Conclusion</h2> <p><span style="margin-left: 10px;"></span> In the world of computer science and software development, mastering Big O Notation is like having a superpower. It empowers developers to make informed decisions about the efficiency and scalability of their algorithms, which is critical in our data-driven and performance-conscious era.</p> <p><span style="margin-left: 10px;"></span> By understanding Big O Notation, you gain insights into how algorithms perform as the size of the input grows. This understanding allows you to optimize your code, ensuring that your applications run faster and handle larger datasets more gracefully. When working on a small personal project, Big O notation might not make much difference, but in a massive enterprise system, choosing the right algorithm can mean the difference between a smooth user experience and a sluggish, unresponsive application.</p> <p><span style="margin-left: 10px;"></span> The examples of Quicksort versus Bubble Sort and Binary Search versus Linear Search illustrate just how crucial algorithm selection can be. Quicksort’s O(n log n) time complexity makes it a go-to for sorting large datasets efficiently, while Bubble Sort’s O(n^2) complexity shows why it’s best left to educational purposes rather than real-world applications. Similarly, Binary Search’s O(log n) complexity highlights its effectiveness for large, sorted datasets compared to the O(n) linear search.</p> <p><span style="margin-left: 10px;"></span> For developers, understanding the Big O complexities of common data structures and algorithms, especially those in the Java Collections Framework, is indispensable. This knowledge helps in selecting the right tool for the job, whether it’s an ArrayList for fast access, a HashMap for quick lookups, or a TreeMap for ordered data.</p> <p><span style="margin-left: 10px;"></span> Backend developers, too, benefit immensely from this knowledge. Efficient database querying, speedy API responses, and effective caching strategies all hinge on the principles of Big O Notation. By optimizing server-side algorithms, you can handle increasing loads and large datasets with ease, ensuring your application remains responsive and performant.</p> <p><span style="margin-left: 10px;"></span> In short, Big O Notation is more than just a theoretical concept; it’s a practical tool that every developer should have in their toolkit. It promotes high-quality code that’s not only efficient and scalable but also maintainable and robust. So, next time you’re writing or reviewing code, take a moment to consider the Big O implications. Feel free to check out these cheat sheets for a quick reference to common Big O complexities! <a href="https://www.bigocheatsheet.com/">https://www.bigocheatsheet.com/</a> and <a href="https://gist.github.com/marcinjackowiak/85f144d0f1ed5fd066d4d2a34961497c">https://gist.github.com/marcinjackowiak/85f144d0f1ed5fd066d4d2a34961497c/</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Big O Notation and code efficiency.]]></summary></entry><entry><title type="html">The Rise of Reactive Programming with Spring WebFlux - A Game Changer or Overkill?</title><link href="https://p-almeida12.github.io/blog/2023/reactive-spring-webflux/" rel="alternate" type="text/html" title="The Rise of Reactive Programming with Spring WebFlux - A Game Changer or Overkill?"/><published>2023-10-18T15:59:00+00:00</published><updated>2023-10-18T15:59:00+00:00</updated><id>https://p-almeida12.github.io/blog/2023/reactive-spring-webflux</id><content type="html" xml:base="https://p-almeida12.github.io/blog/2023/reactive-spring-webflux/"><![CDATA[<p><span style="margin-left: 10px;"></span>Reactive programming has sparked a revolution in the realm of software development. With its capacity to efficiently handle large-scale, highly concurrent systems, it has become the go-to approach for building modern, responsive applications. In the world of Java development, Spring WebFlux has emerged as a formidable framework, offering developers the tools they need to harness the power of reactive programming.</p> <p><span style="margin-left: 10px;"></span>In this article, we embark on a journey through the landscape of reactive programming and its impact on the world of Java development. We’ll delve into the core principles that define reactive programming and explore how it transforms the way we approach application design. We will focus on Spring WebFlux, the driving force behind reactive Java applications, as we examine its capabilities and shed light on why it has gained momentum in recent years.</p> <h2 id="understanding-reactive-programming">Understanding Reactive Programming</h2> <p><span style="margin-left: 10px;"></span>Right now, in the IT community, the term “Reactive” is getting a little bit overloaded/abused, so according to the Reactive Manifesto (https://www.reactivemanifesto.org), the reactive systems are Responsive, Resilient, Elastic and Message Driven. The term “reactive” in the context of programming models revolves around the idea of reacting to change, such as components responding to various events like I/O or user input. Feel free to read the manifesto for a better understanding of this concepts.</p> <p><span style="margin-left: 10px;"></span>Complex systems are built from smaller, interconnected components, and their behavior hinges on the responsiveness of these constituent elements. This implies that Reactive Systems employ a set of design principles to ensure that these responsive properties are consistently exhibited across all levels of scale within the system, enabling seamless composability. In essence, every building block, whether large or small, is designed to exhibit reactive characteristics, allowing them to work in harmony and combine effectively to create a cohesive and adaptable system.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 1 - Reactive System (https://www.reactivemanifesto.org) </div> <p><span style="margin-left: 10px;"></span>Now that we have a better understanding of what the term “Reactive” really stands for, we can dive into Reactive Programming. Reactive programming is an implementation technique, a tool, that focuses on non-blocking, asynchronous execution, a key characteristic of Reactive Systems.</p> <p><span style="margin-left: 10px;"></span>Reactive programming is an asynchronous programming paradigm focused on streams of data an events in a non-blocking way. According to Gerad Berry, a French Computer Scientist, these programs also maintain a continuous interaction with their environment, not the program itself. Interactive programs work at their own pace, while reactive programs only work in response to external demands. That being said, the first one, tends to block threads, leading to performance bottlenecks and decreased system responsiveness. In contrast, the second one, uses non-blocking I/O operations, allowing applications to handle more requests concurrently with a faster response time.</p> <p><span style="margin-left: 10px;"></span>The Non-blocking concept is very important. In Blocking, the code will stop and wait for more data (ie reading from disk, network, etc). Non-blocking in contrast, will process available data, ask to be notified when more is available and then continue. In the images below, we can have a better understanding of what Non-blocking consists.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2 - Multi Thread Server (https://javarevisited.blogspot.com/2017/03/why-we-use-threads-in-java.html) and Figure 3 - Node.js Server (https://strongloop.com/strongblog/node-js-is-faster-than-java/) </div> <p><span style="margin-left: 10px;"></span>Java developers always have been pretty comfortable using Multi Threaded Servers, where we have a thread pool that take a given number os requests. When a given thread receives a request, it will get suspended while is waiting for a resource. This starting and stopping of the threads is pretty common and Java handles it very efficiently, so its not necessarily a bad programming paradigm and it has been around for a long time.</p> <p><span style="margin-left: 10px;"></span>In contrast, we have the Node.js server that uses different techniques to manage the threads. In the Figure 3 above, a request comes in and we have a single thread in loop to the the work, that delegates the requests to async threads as they come in. As we can see we have no waiting threads, at all times all the threads are processing, which can improve efficiency and performance. But this isn’t properly a good thing, imagine that something on the event loop takes a lot of CPU, that can really bring down Node.js performance, not to talk about the callback hell that Node.js is known for. It is a significantly different paradigm because your requests are expected to complete quickly on that event loop and get off of it.</p> <p><span style="margin-left: 10px;"></span>Another feature of reactive programming is the Back Pressure. Back Pressure is the ability of the subscriber to throttle data, to help avoid issues as buffering and blocking. Throttling is the practice of controlling the quantity of data that can be exchanged between two systems within a specific time frame. Typically, this is implemented to avoid one system overwhelming another with an excessive data load or to ensure that an individual user does not excessively deplete a shared resource. The failures are also a little different as well, since exceptions are not thrown in a traditional sense, since it would break the stream. Exceptions are processed by a handler function.</p> <h2 id="what-is-spring-webflux">What is Spring WebFlux?</h2> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_4.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 4 - Spring WebFlux (https://blog.onesaitplatform.com/en/2022/07/13/reactive-programming-spring-webflux/) </div> <p><span style="margin-left: 10px;"></span>WebFlux is a reactive programming model for building web applications and is a part of the Spring Framework ecosystem. Based on the documentation, it was created with two primary needs: Concurrency and Resource Efficiency and Functional Programming. It is built on top of the Reactive Streams API, which provides a model to build web applications on the JVM.</p> <p><span style="margin-left: 10px;"></span>Reactor is the reactive library for Spring WebFlux. It offers the Mono and Flux API types to work with data sequences of 0 to 1 and 0 to many, using a comprehensive set of operators aligned with the ReactiveX operator vocabulary. As a Reactive Streams library, Reactor ensures support for non-blocking back pressure.</p> <p><span style="margin-left: 10px;"></span>Spring WebFlux has two main components: the RouterFunction and the HandlerFunction. The RouterFunction serves the purpose of associating incoming requests with their corresponding HandlerFunction. The role of the HandlerFunction is to manage the request and provide a response. The objective of the Reactive Stream API is to create a standard for asynchronous stream processing with a non-blocking back pressure. There are two main components: the Publisher and the Subscriber. The publisher emits the data and the subscriber consumes it.</p> <p><span style="margin-left: 10px;"></span>For instance, a data repository acting as a Publisher can produce data, while an HTTP server acting as a Subscriber can write this data to the response. The primary purpose of Reactive Streams is to enable the subscriber to control the pace at which the publisher produces data, ensuring a balanced flow of information.</p> <h2 id="spring-webflux--spring-mvc">Spring WebFlux &amp; Spring MVC</h2> <p><span style="margin-left: 10px;"></span>I think by now we can have a pretty good idea where both of these paradigms differ. Although they’re both designed to build web applications, one uses a blocking approach and the other one uses a non-blocking approach. Spring Web MVC traditionally incorporates the servlet API and operates within a servlet container, which are by nature blocking as well as JDBC and JPA. In Spring WebFlux, the web server does not use the servlet container, because it is using a new stack underneath that. Although Spring made a really good job keeping it abstract to us developers, we must keep in mind that Web MVC components are blocking!</p> <p><span style="margin-left: 10px;"></span>But the real question is: which one is better? Is Spring WebFlux that good has it seems to be? And the answer is simple, it depends. I know, cliché, but its my honest opinion and a lot of times, especially in Software Engineering, is actually true. We can’t choose one over the other based only on this, we need to be skeptical and understand what are the needs of the program we are about to develop. That being said, let’s take a look at where and when one paradigm can be better than the other.</p> <h3 id="spring-webflux">Spring WebFlux</h3> <p><span style="margin-left: 10px;"></span>Spring WebFlux is ideal for applications that need to handle a large number of concurrent requests and require high scalability. For example, a high-traffic e-commerce website, that needs to handle a large number of concurrent requests. If your application deals with streams of data or events, such as real-time updates, IoT devices, or message-driven architectures, WebFlux enables handling of asynchronous operations and provides built-in support for WebSocket communication. It’s also really good with microservices and if your team is into functional programming, it will be worth your while for sure!</p> <h3 id="spring-mvc">Spring MVC</h3> <p><span style="margin-left: 10px;"></span>Spring MVC is a suitable choice when your application primarily handles synchronous request processing and doesn’t require the high concurrency and scalability benefits of reactive programming. Spring MVC has a widely adopted and mature ecosystem, making it a dependable choice for many applications. The existence of heavy dependency on Spring MVC libraries or if the project relies on blocking I/O operations, migrate it to Spring WebFlux can be tricky. It really comes down to the needs of your existent program and the experience of the team you’re working with, sometimes Spring MVC is the way to go.</p> <h2 id="performance-considerations">Performance Considerations</h2> <p><span style="margin-left: 10px;"></span>In my GitHub profile, I have repositories where I used Spring MVC and where I used Spring WebFlux and thats the reason I’m writing this article, to share my journey and what I could learn while doing it. So, if we take into consideration the performance of both approaches, we can take this example of my projects.</p> <p><span style="margin-left: 10px;"></span>Let’s consider a scenario where we need to handle multiple concurrent requests for fetching data from a remote service. We’ll compare the performance of Spring WebFlux and Spring MVC in this situation.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 4 - Spring WebFlux example. </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/post1_7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 5 - Spring Web MVC example. </div> <p><span style="margin-left: 10px;"></span>In the WebFlux example, when a non-blocking request is made, the server thread efficiently manages other incoming requests while it awaits the response. This capability empowers the server to handle a larger number of concurrent requests, all with a reduced need of numerous threads. This results in a significant enhancement in scalability, as the server can efficiently serve multiple clients simultaneously.</p> <p><span style="margin-left: 10px;"></span>On the other hand, in the MVC example, synchronous requests are processed, and the server thread remains engaged until the response is received. This conventional approach poses limitations on the number of concurrent requests the server can effectively manage. Consequently, this method may experience performance degradation when subjected to high workloads, as the server’s resources can become bottlenecked due to the blocking nature of request processing.</p> <p><span style="margin-left: 10px;"></span>According to a <a href="https://medium.com/deno-the-complete-reference/spring-boot-vs-spring-webflux-performance-comparison-for-hello-world-case-386da4e9c418">Medium</a> post, where they compare WebFlux to Web MVC, the Spring Boot (threadpool), Spring WebFlux demonstrates noticeable performance advantages, particularly in terms of requests per second and response times. It achieves approximately double the RPS compared to Spring Boot while maintaining a similar resource cost. The performance characteristics differ based on concurrency levels. At lower concurrency levels, Spring WebFlux exhibits superior median response times. However, at higher levels of concurrency, Spring Boot outperforms Spring WebFlux. Feel free to read their post and analyze their research.</p> <p><span style="margin-left: 10px;"></span>But keep in mind, reactive and non-blocking programming may not inherently make applications run faster. They can enhance performance in certain scenarios, such as when using WebClient for parallel remote calls, but typically, they entail more complex implementation and may slightly increase processing time. Never the less, their primary advantage lies in the ability to scale effectively with a fixed number of threads and reduced memory usage. This scalability improves application resilience under heavy loads, offering more predictable performance. The true benefits of reactive and non-blocking become apparent in situations with latency, including slow and unpredictable network, where the reactive approach excels and can lead to significant performance improvements.</p> <h2 id="the-final-verdict">The Final Verdict</h2> <p><span style="margin-left: 10px;"></span>The moment we were all waiting for: the verdict. At least mine. After reading multiple posts of other fellow developers and enthusiasts, some think that Reactive Programming isn’t that big of a deal and others think it will take Java to the next level. Throughout this section I will try to be as impartial as possible, so we can actually take something from this and make up our own minds.</p> <p><span style="margin-left: 10px;"></span>Let’s start with the concept of Non-Blocking, if we need to make a call, then block to wait for the response and then handle the response because we need that same thread, we can’t and we’re not using Reactive, because we can get into an event loop and stop the application. What I’m trying to say is that everything that uses ThreadLocal, the Java special class that allows us to store data that will be accessible only by a specific thread, is not compatible with reactive. You might think “That isn’t that big of a deal, just don’t use it!”, well I’m afraid that sometimes it might not be possible. Like I said before, JDBC, for example, is intrinsically blocking, its not something we can switch on and off. It is dependent of the ThreadLocal to allow rollbacks, because it holds the transaction, and if we’re working with old JDBC databases, migration can be painful (trust me). The database driver must use the R2DBC spec in order to work with non-blocking calls. One important thing to mention, that sometimes can go unnoticed, is fact that REST calls aren’t blocking, because, in Spring WebClient, they’re not thread-dependent, meaning that the request thread doesn’t have to be the response thread.</p> <p><span style="margin-left: 10px;"></span>If f your application is already handling loads efficiently using traditional MVC or by resorting to horizontal scaling, it may not be the most prudent business decision to opt for WebFlux. In such cases, the additional complexity and resource allocation required by WebFlux might outweigh the potential benefits it offers, making it less compelling from a cost-benefit perspective. So reactive and non-reactive paradigms cannot be mixed, which means that the application has to be reactive end to end. It’s not impossible, but integrating blocking code into a reactive pipeline can be challenging for what I could gather and is an anti-pattern approach for me. Not to talk about debugging, the process that we learnt in the first day of college can become quite hard if the pipeline isn’t correctly built.</p> <p><span style="margin-left: 10px;"></span>Apart from the performance benefits, I found it cognitively complex, hard to read nested code, hard to debug and divides the ecosystem efforts. It’s hard enough to keep complicated synchronous code working and adding the complexity of these non-blocking apis only further complicates already complicated code. This could have been the projects issue. By harder to maintain I mean adding certain features. Sometimes this required to rewrite whole chains instead of simply adding to the existing code. Plain imperative sequential code is much much easier to reason about, and therefore maintain and evolve, than reactive code. This can lead to a team spending more time having to fix technical issues than they are adding business value and for someone who doesn’t have that much experience like me, the code can be unreadable, unlike other approaches that even though we’re not used to we can get around.</p> <p><span style="margin-left: 10px;"></span>As i was scavenging the internet, I began to understand that almost everyone doesn’t really need reactive, they think it will be the savior and it will resolve all their performance problems. Well that’s most definitely not true, WebFlux is used for very specific needs where the advantages surpass the downsides. And with the rise of Loom Project, these APIs begin to stay behind. I strongly recommend you to check out the Loom project, it can be a game changer. While I remain skeptical that Loom will serve as a silver bullet solution for these issues, I do hold the hope that the adoption of more linear control flows will enhance the readability and writability of code. There’s a certain comfort in following the familiar path of writing straightforward imperative code. Additionally, with the impending arrival of Virtual Threads, the value proposition of transitioning to a reactive approach appears to be somewhat diminished. These advancements lead me to question whether the adoption of reactive programming is as compelling as it once was.</p> <p><span style="margin-left: 10px;"></span>In a nutshell, if you find yourself in a position where you are willing to make a trade-off, sacrificing a degree of simplicity in exchange for the potential performance enhancements, then embracing reactive programming could be a strategic decision that aligns with the specific needs and goals of your project. It’s an approach that allows you to harness the power of asynchronous, non-blocking operations to cater to high-concurrency scenarios, thereby unlocking new possibilities for your application’s scalability and responsiveness.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Reactive Programming and Spring WebFlux]]></summary></entry></feed>